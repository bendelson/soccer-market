{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "async def scrape_with_retries(leagues, start_year=2004, end_year=2025, max_retries=20):\n",
    "    df_results = []\n",
    "    remaining = []\n",
    "\n",
    "    for league_name, base_url in leagues.items():\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            full_url = f\"{base_url}?saison_id={year}\"\n",
    "            remaining.append({\"league\": league_name, \"year\": year, \"url\": full_url})\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\",\n",
    "            locale=\"de-DE\"\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        attempt = 1\n",
    "        while remaining and attempt <= max_retries:\n",
    "            print(f\"\\nðŸ” Attempt {attempt} with {len(remaining)} URLs to process...\")\n",
    "            current_batch = remaining\n",
    "            remaining = []\n",
    "\n",
    "            for entry in current_batch:\n",
    "                league = entry[\"league\"]\n",
    "                year = entry[\"year\"]\n",
    "                url = entry[\"url\"]\n",
    "\n",
    "                try:\n",
    "                    print(f\"ðŸŒ {league} {year}: Loading {url}\")\n",
    "                    await page.goto(url, timeout=60000)\n",
    "                    await page.wait_for_load_state(\"networkidle\", timeout=30000)\n",
    "                    await page.wait_for_timeout(random.randint(1000, 3000))\n",
    "\n",
    "                    content = await page.content()\n",
    "                    if \"Keine Daten verfÃ¼gbar\" in content:\n",
    "                        print(f\"ðŸš« {league} {year}: No data available.\")\n",
    "                        continue\n",
    "\n",
    "                    xpath = '/html/body/div[2]/main/div[1]/div[1]/div[2]/div[2]/div/table/tfoot/tr/td[6]'\n",
    "                    locator = page.locator(f'xpath={xpath}')\n",
    "                    await locator.wait_for(timeout=5000)\n",
    "\n",
    "                    value = await locator.text_content()\n",
    "                    if value:\n",
    "                        value_clean = value.strip()\n",
    "                        print(f\"âœ… {league} {year}: {value_clean}\")\n",
    "                        df_results.append({\n",
    "                            \"league\": league,\n",
    "                            \"year\": year,\n",
    "                            \"value\": value_clean\n",
    "                        })\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ {league} {year}: XPath found, but empty.\")\n",
    "                        remaining.append(entry)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {league} {year}: Failed â€” {str(e)}\")\n",
    "                    remaining.append(entry)\n",
    "\n",
    "            attempt += 1\n",
    "        await browser.close()\n",
    "\n",
    "    return pd.DataFrame(df_results)\n",
    "\n",
    "async def main():\n",
    "    leagues = {\n",
    "        \"MLS Soccer \": \"https://www.transfermarkt.de/major-league-soccer/startseite/wettbewerb/MLS1/plus/\",\n",
    "        \"Ligue 1\": \"https://www.transfermarkt.de/ligue-1/startseite/wettbewerb/FR1/plus/\",\n",
    "        \"Saudi Pro League\": \"https://www.transfermarkt.de/saudi-pro-league/startseite/wettbewerb/SA1/plus/\",\n",
    "        \"Bundesliga\": \"https://www.transfermarkt.de/bundesliga/startseite/wettbewerb/L1/plus/\",\n",
    "        \"2. Bundesliga\": \"https://www.transfermarkt.de/2-bundesliga/startseite/wettbewerb/L2/plus/\",\n",
    "        \"Premier League\": \"https://www.transfermarkt.de/premier-league/startseite/wettbewerb/GB1/plus/\",\n",
    "        \"Championship\": \"https://www.transfermarkt.de/championship/startseite/wettbewerb/GB2/plus/\",\n",
    "        \"La Liga\": \"https://www.transfermarkt.de/laliga/startseite/wettbewerb/ES1/plus/\",\n",
    "        \"Serie A\": \"https://www.transfermarkt.de/serie-a/startseite/wettbewerb/IT1/plus/\"\n",
    "           }\n",
    "    print(\"ðŸŒ Starting transfermarkt scraper...\")\n",
    "\n",
    "    df = await scrape_with_retries(leagues, start_year=2004, end_year=2025)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    df.to_excel(f\"transfermarkt_results_{timestamp}.xlsx\", index=False)\n",
    "    print(\"ðŸ“ Data saved.\")\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
